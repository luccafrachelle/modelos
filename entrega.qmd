---
title: "Entrega trabajo final modelos lineales"
format: pdf
author: "Lucca Frachelle , Valentina Solidni , Cecilia Waksman"
date: "`r Sys.Date()`"
editor: visual
echo: false
---

# Introducción

Este trabajo consiste en un análisis de la incidencia de ciertos factores sobre la presión sanguínea en personas hipertensas. Los factores que se tomarán en cuenta para ello son: edad, peso, superficie corporal, duración desde que a la persona le diagnosticaron hipertensión, el pulso en estado basal y un índice de estrés.

Para ello se utilizarán df de un estudio realizado en una policlínica universitaria y se realizará un modelo de regresión lineal múltiple, dónde la variable de respuesta, Y, es la presión arterial (*presion_art*) y las variables explicativas serán seleccionadas de las nombradas anteriormente (las cuales formarán la matriz X).

El modelo se podrá escribir como $Y=X\beta + \epsilon$, donde $\beta$ es un vector de parámetros a estimar.

# Supuestos a cumplir

Para poder obtener conclusiones confiables, el modelo debe cumplir con determinados supuestos

-   no multicolinealidad: exacta ni aproximada, para asegurar que la matriz X sea de rango completo (conformable),

-   linealidad: la relación entre variables expicativas y la respuesta debe ser aproximadamente lineal,

-   homoscedasticidad: la varianza de los errores no depende de ninguna de las variables explicativas,

-   normalidad: los errores del modelo deben presentar una distribución normal,

-   atípicos/influyentes: si bien no es un supuesto en si mismo, es recomendable identificar observaciones atípicas e influyentes al modelo.

# Librerias

```{r}
#| output: FALSE
library(readxl)
library(tidyverse)
library(GGally)
library(car)
library(skedastic)
library(robustbase)
library(tseries)
library(knitr)

```

```{r}
#| output: false
#df <- read_excel("data/datos_presion.xlsx")
df = read_excel('./data/datos_presion.xlsx')
df <- df %>% dplyr::select(-id)
```

# Análisis exploratorio

```{r}
#| echo: false
summary(df) %>% kable()
```

Los datos consisten en mediciones de los siguientes parámetros:

-   **Edad**: Varía entre 44 y 56 años, con una mediana de 48 años.

-   **Peso**: Oscila entre 65.3 kg y 84.4 kg, con una media de 75.72 kg.

-   **Superficie Corporal**: Se encuentra entre 1.69 m² y 2.33 m², con una media de 2.019 m².

-   **Duración de la Hipertensión**: Registrada entre 2.5 y 12.8 años, con una mediana de 6.3 años.

-   **Pulso** : Varía de 61 a 80 pulsaciones por minuto, con una media de 69.86 pulsaciones por minuto.

-   **Índice de Estrés**: Mide entre 0 y 100, con una media de 53.05.

-   **Presión Arterial** : Oscila entre 101 mmHg y 129 mmHg, con una media de 114.4 mmHg.

```{r, fig.cap="Distribución y Correlación", label:fig-plot0} 
#| echo: false
ggpairs(df)
```

### Análisis de Distribución y Correlación

1.  **Distribución de Variables**

    -   **Edad**: La distribución de la edad muestra una concentración alrededor de los 48-50 años.

    -   **Peso**: La distribución del peso es relativamente normal, con una media alrededor de 75 kg.

    -   **Superficie Corporal**: La superficie corporal también sigue una distribución normal, centrada cerca de 2.0 m².

    -   **Duración de la Hipertensión**: La duración de la hipertensión muestra una mayor dispersión, pero con una tendencia hacia valores más bajos.

    -   **Pulso**: El pulso muestra una distribución concentrada entre 65 y 75 pulsaciones por minuto.

    -   **Estrés**: El índice de estrés varía considerablemente, pero con una mayor concentración en valores bajos.

    -   **Presión Arterial**: La presión arterial tiene una distribución aproximadamente normal, centrada alrededor de 115 mmHg.

2.  **Correlaciones Significativas**

    -   **Edad y Peso**: Existe una correlación positiva significativa entre la edad y el peso (corr = 0.339).

    -   **Peso y Superficie Corporal**: La correlación entre el peso y la superficie corporal es muy alta (corr = 0.874), lo cual es esperable ya que ambos parámetros están relacionados físicamente.

    -   **Superficie Corporal y Peso**: Esta correlación refuerza la relación entre estas dos variables (corr = 0.874).

    -   **Duración de la Hipertensión y Edad**: Hay una correlación positiva moderada entre la duración de la hipertensión y la edad (corr = 0.544).

    -   **Pulso y Peso**: La correlación entre el pulso y el peso es positiva y significativa (corr = 0.533).

    -   **Estrés y Peso**: Existe una correlación moderada entre el estrés y el peso (corr = 0.533).

    -   **Presión Arterial y Edad**: La presión arterial está positivamente correlacionada con la edad (corr = 0.486).

    -   **Presión Arterial y Peso**: Hay una correlación significativa entre la presión arterial y el peso (corr = 0.755).

    -   **Presión Arterial y Superficie Corporal**: Existe una correlación positiva entre la presión arterial y la superficie corporal (corr = 0.810).

    -   **Presión Arterial y Pulso**: La correlación entre la presión arterial y el pulso es significativa (corr = 0.533).

```{r}
mod = lm(presion_art ~ ., data = df)
```

## Diagnostico del modelo

## Multicolinealidad

```{r}
#| echo: false
vif(mod)
```

Se observa que al hacer el vif la variable que tenía un valor mas alto indicando una alta multicolinealidad era la variable "peso", por esta razón fue que se descidio eliminarla del modelo. Se elimina la variable peso que tiene un el VIF mas alto. Condice ya que peso estaba fuertementemente correlacionada con la varaible superfice corporal, por lo que tiene sentido que estas dos tengan un vif alto ya que de cierta forma compiten por explicar la misma variablidad.

```{r}
mod = update(mod, . ~ . - peso)
```
```{r}
#| echo: false
summary(mod)
```

```{r}
#| echo: false
vif(mod)
```

Todos los VIF son con diferencia menores a 5, por lo que no hay multicolinealidad. Se puede seguir con el analisis.

## Lineanidad

```{r, warning=FALSE, fig.cap="Linealidad", label:fig-plot1}
#| echo: false
crPlots(mod)
```

Parece no haber problemas de linealidad en el modelo. Ya que los residuos no presentan un patron claro , como dispersión o curvatura a lo largo de los valores de x.Por lo que se puede seguir con el analisis.

## Homoscedasticidad

Atípicos

```{r}
#| echo: false
ncvTest(mod)
```

```{r}
#| echo: false
breusch_pagan(mod)
```

#### **ncvTest**

-   **Hipótesis**:

    -   **Hipótesis Nula (H0)**: La varianza de los residuos es constante (homocedasticidad).

    -   **Hipótesis Alternativa (H1)**: La varianza de los residuos no es constante (heterocedasticidad).

-   **Procedimiento**:

    -   El ncvTest examina la relación entre los valores ajustados (predicciones del modelo) y la varianza de los residuos.

    -   Se ajusta un modelo de regresión para predecir los residuos en función de los valores ajustados.

    -   Se calcula un estadístico de prueba basado en esta relación.

    -   El estadístico de prueba sigue una distribución chi-cuadrado.

    Un p-valor alto sugiere que no hay evidencia suficiente para rechazar la hipótesis nula, indicando homocedasticidad.

    -   Un p-valor bajo indica heterocedasticidad.

#### **Breusch-Pagan Test**

-   **Hipótesis**:

    -   **Hipótesis Nula (H0)**: La varianza de los residuos es constante y no depende de las variables independientes (homocedasticidad).

    -   **Hipótesis Alternativa (H1)**: La varianza de los residuos depende linealmente de las variables independientes (heterocedasticidad).

-   **Procedimiento**:

    -   El test de Breusch-Pagan examina si la varianza de los residuos depende linealmente de las variables independientes del modelo original.

    -   Se realiza una regresión auxiliar de los residuos al cuadrado contra las variables independientes originales.

    -   Se calcula un estadístico de prueba basado en la regresión auxiliar.

    -   El estadístico de prueba sigue una distribución chi-cuadrado.

Como los dos p-values son mas grandes que 0.7 no hay problemas de heteroestaticidad.

## Normalidad de los residuos

```{r,fig.cap="Normalidad de los residuos", label:fig-plot2}
#| echo: false 
plot(density(rstudent(mod)))
```

Se observa como la desnidad parece normal. Sin embargo las colas no son simetricas. La cola inferior es bastante más pesada que la superior. Lo que puede dar algun indicio de que los resiudos no se distriubuyen normal.

```{r,fig.cap="Normalidad de los residuos", label:fig-plot3}
#| echo: false
plot(density(rstudent(mod)))
```
```{r, warning=FALSE, fig.cap="Comparación de los cuantiles teóricos y empíricos", label:fig-plot4}
#| echo: false 
n <- nrow(df)
z_i <- qnorm(seq(n)/(n + 1))
qq <- data.frame(teoricos = z_i,
                 empiricos = sort(rstudent(mod)))
library(ggplot2)
ggplot(qq, aes(x = teoricos, y = empiricos)) +
  geom_point() +
  xlab('Cuantiles teoricos') +
  ylab('Cuantiles empiricos') +
  geom_abline(slope = 1, intercept = 0, col = 2, size = 1.5)#comparación entre disrtib de los df y distrib normal

```


Un poco de la misma forma se observa como la parte inferior de la cola es la que peor se ajusta a la recta por lo que da indicios de no es del todo normal.

```{r}
#| echo: false
shapiro.test(rstudent(mod))
jarque.bera.test(rstudent(mod))#rechazo al 5
ks.test(rstudent(mod), 'pnorm')

```

El test Jarque-Bera tiene un p-value menor que 0.05, por lo que se rechaza la hipotesis nula de que los residuos son normales. Sin embargo, el test de Shapiro-Wilk y el test de Kolmogorov-Smirnov no rechazan la hipotesis nula. Por lo que no se puede afirmar que los residuos no son normales. Se va a intervenir el modelo para ver si se puede mejorar la normalidad de los residuos. Como se menciono anteriormente la variable edad puede no ser lineal, por lo que se va a transformar la variable edad para ver si se puede mejorar la normalidad de los residuos.

## Atípicos

```{r, fig.cap=" Valores Atípicos", label:fig-plot5 }
#| echo: false
res <- rstudent(mod)
yhat <- fitted(mod)

which(abs(res)>3)

library(ggplot2)
ggplot(mod, aes(x=yhat, y= res))+
  geom_point()+
  geom_hline(yintercept = -3,color="darkblue")+
  geom_hline(yintercept = 3,color="darkblue")
```

## Presencia de Influyentes

Para detectar la presencia de influyentes lo que se va a realizár es utilizar dos métodos: Leverage y Distancia de Cook. 

**Leverage:** Este indicador es útil para determinar la influencia de cada observación sobre los valores ajustados, se esconde en los valores de la diagonal de la matriz H. Los puntos con un alto leverage tienen un potencial mayor para influir en la estimación de los coeficientes del modelo de regresión.Un punto de leverage mayor que 2(k+1)/n, donde k es el número de predictores y n es el número de observaciones, se considera un punto alto de leverage.

**Distancia de Cook:** Este indicador cuantifica el cambio en el vector de estimaciones luego de remover la i-ésima observación.Di cuantifica el cambio en el vector de valores ajustados.Para determinar si alguna observación tiene una influencia significativa Di>4/n.

Leverage:

```{r}
#| echo: false
h_i <- influence(mod)$hat
D_i <- cooks.distance(mod)
df_influencia <- data.frame(i = 1:nrow(df),
                            h_i = h_i,
                            D_i = D_i)
```

```{r, fig.cap="Leverage", label:fig-plot6}
#| echo: false
ggplot(df_influencia, aes(x = i, y = h_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = h_i)) +
  xlab('') +
  ylab(expression(h[i])) +
  geom_abline(slope = 0, intercept = 2*length(coefficients(mod))/nrow(df), col = 2, linetype = 'dashed') +
  ggtitle('Leverage')
```

Se puede observar que por el indicador de Leverage, se puede observar tres precencias de datos influyentes.Estos puntos podrían tener un impacto significativo en los resultados del análisis. En etapass posteriores, se evaluará como manejarlos, ya sea mediante su eliminación o una intervención.

```{r, fig.cap="Distancia de Cook", label:fig-plot7}
#| echo: false
ggplot(df_influencia, aes(x = i, y = D_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = D_i)) +
  xlab('') +
  ylab(expression(D[i])) +
  geom_abline(slope = 0, intercept = 4/nrow(df), col = 2, linetype = 'dashed') +
  ggtitle('Distancia de Cook')
```
En este caso, hay más datos influyentes que en el caso de Leverage. Sin embargo, se va a tratar de seguir el mismo enfoque, considerando la eliminación de estos datos o intervenirlos para poder continuar con el analisis.

A continuación, se procederá a intervenir los datos, separandolos según los dos enfoques. Se evaluará cuál de los dos métodos es más conveniente para nuetsro análisis.

Intervención de influyentes según Levrage:

```{r}
#| echo: false
df$I38 <- 0
df$I38[38] <- 1
df$I73 <- 0
df$I73[73] <- 1
mod_I <- lm(presion_art ~ . -peso, data = df)
vif(mod_I)
#obs 58 es influyente en ambos gráficos pero aceptamos normalidad si lo quitamos
```

```{r, fig.cap="Linealidad", label:fig-plot8}
#| echo: false
crPlots(mod_I)
```

```{r, warning=FALSE}
#| echo: false
ncvTest(mod_I)
breusch_pagan(mod_I)
```

```{r}
#| echo: false
shapiro.test(rstudent(mod_I))
jarque.bera.test(na.omit(rstudent(mod_I)))
ks.test(rstudent(mod_I), 'pnorm')

```

Para este caso, se intervinieron los datos 38 y 73, que fueron identificados como influyentes en el gráfico de este indicador. 

-   Test de Multicolinealidad: Los valores de VIF fueron todos inferiores a 5, indicando ausencia de multicolinealidad significativa.

-   Test de Linealidad: Todas las variables siguen una relación lineal adecuada.

-   Test de Homocedasticidad: Se rechazó la hipótesis nula, con un p-valor de 0.704, indicando que no hay un problema de heterocedasticidad.

-   Test de Normalidad: Se utilizaron los métodos de Shapiro-Wilj, Jarque-Bera y Kolmogorov-Smirnoc para evaluar normalidad en los residuos. Los tres métodos dan un p-valor mayor a 5% por lo tanto se scepta la normalidad.



Interviención de influyentes según distancia de Cook:

```{r}
#| echo: false
df$I62 <- 0
df$I62[62] <- 1
mod_II <- lm(presion_art ~ . -peso -I38 -I73, data = df)
vif(mod_II)
# si se borra intervención de influyentes de Leverage, debemos actualizar nuestro modelo borradno "-I38 -I73".
```

```{r, warning=FALSE, fig.cap="Linealidad", label:fig-plot9}
#| echo: false
crPlots(mod_II)
```
```{r}
#| echo: false
ncvTest(mod_II)
```

```{r}
#| echo: false
breusch_pagan(mod_II)
```

```{r}
#| echo: false
shapiro.test(rstudent(mod_II))
jarque.bera.test(na.omit(rstudent(mod_II)))
ks.test(rstudent(mod_II), 'pnorm')
```
Se realizó el mismo analisis que para el método de Leverage.
Para este caso, se intervinieron varios datos, pero probando llegamos a la conclución que solo sacando la variable "peso" e interviniendo el dato 62, llegamos a cumplir con todos los supues. 
-   Test de Multicolinealidad: Los valores de VIF fueron todos inferiores a 5, indicando ausencia de multicolinealidad significativa.
-   Test de Linealidad: Todas las variables siguen una relación lineal adecuada.
-   Test de Homocedasticidad: Se rechazó la hipótesis nula, con un p-valor de 0.82783, indicando que no hay un problema de heterocedasticidad.
-   Test de Normalidad: Se utilizaron los métodos de Shapiro-Wilj, Jarque-Bera y Kolmogorov-Smirnoc para evaluar normalidad en los residuos. Los tres métodos dan un p-valor mayor a 5% por lo tanto se scepta la normalidad.


Tras completar estos dos análisis, se identificó que las variables "duracion_hip" y "stress" no son significativas en el modelo. En consecuancia, se procederá a repetir todo el análisis excluyendo estas dos variables.
Acontinuación se puede ver como estas dos variables que se menciono anteriormente no son singificativas en el modelo.
```{r}
#| echo: false
summary(mod_II)
# Intervención significativa
# duracion_hip y stress son no significativas
```
Modelo sin variables no significativas:


Se procedió eliminar las variables no significativas mencionadas anteriormente, "duracion_hip" y "stress" del modelo que creamos anteriormente. Luego, se generó un resumen del modelo para verificar la significancia de las variables restantes.

```{r}
#| echo: false
mod_II2 = update(mod_II, . ~ . - peso - stress -duracion_hip)
#modelo sin stress y/o duracion_hip no acepta normalidad
summary(mod_II2)
```

```{r}
#| echo: false
shapiro.test(rstudent(mod_II2))
jarque.bera.test(na.omit(rstudent(mod_II2)))
ks.test(rstudent(mod_II2), 'pnorm')
```
Se realizó una prueba de Normalidad utilizando los métodos de Shapiro-Wilj, Jarque-Bera y Kolmogorov-Smirnoc. Los resultados indicaron que el p-valor de los métodos Shapiro-Wilj y Jarque-Bera fue inferior al 5%, lo cual sugiere que no se cumple el supuesto de normalidad para los residuos del modelo.

Al no lograr cumplir con el este de Normalidad incluso después de eliminar las variables significativas, se pprocedió a crar otro modelo excluyendo esas variables del análisis.

```{r}
df = read_excel('./data/datos_presion.xlsx')
df <- df %>% dplyr::select(-id)
mod2 <- lm(presion_art~.-peso-stress-duracion_hip, data=df)
```
```{r}
#| echo: false
vif(mod2)
```

```{r}
#| echo: false
summary(mod2)
```

```{r}
#| echo: false
h_i2 <- influence(mod2)$hat
D_i2 <- cooks.distance(mod2)
df_influencia2 <- data.frame(i = 1:nrow(df),
                            h_i = h_i2,
                            D_i = D_i2)
```

```{r, warning=FALSE, fig.cap="Leverage", label: fig-plot10}
#| echo: false
ggplot(df_influencia2, aes(x = i, y = h_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = h_i)) +
  xlab('') +
  ylab(expression(h[i])) +
  geom_abline(slope = 0, intercept = 2*length(coefficients(mod2))/nrow(df), col = 2, linetype = 'dashed') +
  ggtitle('Leverage')
```

```{r, warning=FALSE, fig.cap="Distancia de Cook", label:fig-plot11}
#| echo: false
ggplot(df_influencia2, aes(x = i, y = D_i)) +
  geom_point() +
  geom_segment(aes(x = i, xend = i, y = 0, yend = D_i)) +
  xlab('') +
  ylab(expression(D[i])) +
  geom_abline(slope = 0, intercept = 4/nrow(df), col = 2, linetype = 'dashed') +
  ggtitle('Distancia de Cook')
```

```{r}
#| echo: false
at_1 <- df_influencia2 %>% arrange(desc(D_i)) %>% head(5) %>% pull(i)
at_2 <- df_influencia2 %>% arrange(desc(h_i)) %>% head(5) %>% pull(i)
```

Atípicos:

```{r, warning=FALSE, fig.cap="Atípicos", label:fig-plot12}
#| echo: false
res <- rstudent(mod2)
yhat <- fitted(mod2)

which(abs(res)>=3)

library(ggplot2)
ggplot(mod2, aes(x=yhat, y= res))+
  geom_point()+
  geom_hline(yintercept = -3,color="darkblue")+
  geom_hline(yintercept = 3,color="darkblue")

#Obs 62 
```

Quitando obs atípica 62

```{r}
#| echo: false
df <- df[-62,]
mod_sin62 <- lm(presion_art ~ .-peso- stress -duracion_hip , data=df)
shapiro.test(rstudent(mod_sin62))
jarque.bera.test(na.omit(rstudent(mod_sin62)))
ks.test(rstudent(mod_sin62), 'pnorm')#no acepta normalidad
```
Después de repetir todo el procedimiento del analisis, se identificó que el dato 62 era un valor átipico. Se decidió intervenirlo y estudiar nuevamente la normalidad de los residuos utilizando los metodos Shapiro-Wilj, Jarque-Bera y Kolmogorov-Smirnoc, como ya se realizo anteriormente. Se observó que solo el método de Kolmogorov-Smirnoc arrojó un p-valor superior al 5%, mientras que los otros dos métodos fueron inferiores a 5%, indicando que no se cumple el supuesto de normalidad.

Debdio a que se utilizaron diversas estrategias para cumplir con el supuesto de normalidad sin éxito, se optó por utilizar el método de Randomize, el cual se describirá en detalle posteriormente.


## Randomization Test

Una alternativa al método convencional para la validación de un modelo es el uso de métodos robustos ante el no cumplimiento de ciertos supuestos. En las etapas de diagnóstico anteriormente planteadas se ha rechazado el supuesto de normalidad, por lo que en este apartado se utilizará la *prueba basada en permutaciones* o *randomization test*, método el cual prescinde de dicho supuesto (o cualquier otro supuesto referente a la distribución de los datos).

\

El mismo consiste en extraer P muestras aleatorias con reposición de los datos; como los mismos ya son una muestra, a estas "sub-muestras" las llamamos *réplicas* y son del mismo tamaño que los datos. Posteriormente se particiona el problema en modelos RLS, tantos como variables explicativas hayan, de tal forma que se obtenga una nueva versión de la variable de interés en cada modelo libre del efecto de las demás variables.

Para cada RLS y en cada réplica, se calcula la estimación del parámetro $\hat\beta_j$ correspondiente y su desvío estimado, y en función de los mismos se calcula el estadístico de interés, en este caso el mismo es el estadístico t, siendo este:

$$t=\frac{\hat\beta_j}{\widehat {desvío}}$$

A partir de esta colección de valores de t se aproximará la distribución del estadístico t y se calcula un p-valor como la proporción de valores de la colección de t que pertenecen al rango $(-|t_{obs}|,|t_{obs}|)$ (frente al total de los mismos), siendo $t_{obs}$ el valor del estadístico t obtenido en las prueba de hipótesis individual del método convencional.

Si los p-valores obtenidos en la prueba de permutaciones son similares a los obtenidos en la prueba de hipótesis individual, el modelo es válido, aún sin necesidad de cumplir el supuesto de normalidad.

```{r}
#| echo: false
# aleatoricemos 'P' veces
P <- 1000

# funcionas auxiliares
h <- function(y, x, X){
  # Esta funcion auxiliar 'remueve' el efecto de las columnas
  # de X en x y en Y
  if (class(X) != 'matrix') X <- as.matrix(X)
  H <- X%*%solve(t(X)%*%X)%*%t(X)
  y1 <- y - y%*%H
  x1 <- x - x%*%H
  return(list(ye    = as.numeric(y1),
              equis = as.numeric(x1)))
}
estima <- function(h){
  # Esta funcion auxiliar estima el parametro de la pendiente
  # en una RLS que no incluye constante.
  # Usa como insumo el resultado de la funcion h()
  sum(h$ye*h$equis)/sum(h$equis^2)
}
desvio <- function(h){
  # Esta funcion auxiliar estima el desvio del estimador de la pendiente
  # en un modelo de RLS que no incluye la constante.
  # Usa como insumo el resultado de la funcion h()
  b <- sum(h$ye*h$equis)/sum(h$equis^2)
  r <- h$ye - b*h$equis
  n <- length(h$ye)
  sqrt((sum(r^2)/(n-1))/sum(h$equis^2))
}
```

```{r}
#| echo: false
# Una funcion que haga todo el trabajo
randomize <- function(mod, P = 1000){
  # Esta funcion aproxima los p-valores de las pruebas de significacion
  # individual mediante 'P' permutaciones aleatorias 
  t_stat <- coef(summary(mod))[,3]
  k   <- length(t_stat)
  est <- matrix(NA, P, k)
  mm  <- mod$model
  Y   <- mm[,1]
  X   <- cbind(1,mm[,-1])
  
  for (i in 1:P){
    tes <- rep(NA, k)
    for (j in 1:k){
      # se quita el efecto de las demas variables
      h1 <- h(Y, X[,j], X[,-j])
      # se permuta
      h1$ye <- sample(h1$ye)
      # se estima el parametro
      b1 <- estima(h1)
      # se estima el desvio
      sb1 <- desvio(h1)
      # se almacena el estadistic 't'
      tes[j] <- b1/sb1 
    }
    est[i,] <- tes
  }
  # se calculan los p-values bilaterales
  t_stat <- matrix(rep(abs(t_stat), P),nrow = P, byrow = TRUE)
  pv <- apply(est > t_stat, 2, mean)
  pv <- pv + apply(est < -t_stat,2,mean)
  
  smod <- coef(summary(mod))
  smod <- cbind(smod, pv)
  colnames(smod)[5] <- 'Pr(>|t|)_rand'
  return(smod)
}
set.seed(2100)
round(randomize(mod2),6)
```

Al comparar los p-valores de la prueba de significación individual y de la prueba de permutaciones, observamos que los resultadosson relativamente similares, por lo que el modelo es válido aunque sus errores no se distribuyan de forma normal.


## Evaluación del desempeño predictivo del modelo

Para evaluar la actuación del modelo, se debe exponer el mismo a un nuevo conjunto de datos. En este caso, al no contar con otros datos, mas que los que son utilizados para crear el modelo, se acude a métodos de *validación cruzada*, en este caso se usa el método denominado *Leave one out* (LOOCV).

El mismo consiste en quitar una observación del dataset y calcular los coeficientes del modelo con este nuevo subconjunto de datos. Esto se lleva a cabo de manera iterativa con cada una de las observaciones de nuestros datos. En cada iteración se predice además el valor de la variable de respuesta de la observación quitada en función de los valores de las variables explicativas en esta observación y de las nuevas estimaciones de los parámetros del modelo.

Posteriormente se calcula el $R^2$ de los resultados obtenidos por este método, es decir:

$$R^2 = 1- \frac{SCRes}{SCTotal} =1- \frac{\sum_{i=1}^{n}(y_i - \hat{yi})^2}{\sum_{i=1}^{n}(yi - \bar{y})^2}$$

donde SCRes es la suma de los cuadrados de los residuos y SCTotal es la suma de los cuadrados Totales. En nuestros datos y, la variable de respuesta, es presion_ert.

```{r}
#| echo: false
n=nrow(df)
pred <- rep(NA,n)

for(i in 1:n){
  df_i <- df[-i,]
  mod_i <- update(mod2, data = df_i)
  pred[i] <- predict(mod_i, newdata = df[i,])
}

#R^2 para las predicciones del Leave one out

R2 <- 1-((sum((df$presion_art - pred)^2))/ (sum((df$presion_art - mean(df$presion_art))^2)))
R2

summary(mod2)$r.squared
```

EL $R^2$ se encuentra por encima del 70%, lo cual permite afirmar que el mismo explica sificientemente bien los datos de la muestra.

Se observa que el $R^2$ por el método LOOCV es un 3,5% más bajo que el $R^2$ de la prueba de significación global. Esto se debe a que el modelo predice mejor los datos con los que fue creado en comparación con datos nuevos; a este efecto se le llama *overfitting*. En nuestro caso el overfitting es relativamente bajo. Podemos afirmar entonces que el modelo es competente en sus predicciones.

## Conclusión:

Para finalizar se puede concluir que el modélo de regresión lineal multiple proporciona una buena representación de la relación entre las variables eplicativas y la variable de respuesta (presión arterial). Luego de pasasr ciertos desafíos con la normalidad de los residuos, se ha confirmado que el modelo es fiable y tiene un buen desempeño predictivo. Por lo tanto, se puede decir que el mdoelo es adecuado para el propósito del análisis y puede ser utilizado para predecir la presión arterial basadas en las variables incluidas en el estudio.

